np.random.normal function has three primary parameters that control the output: loc, scale, and size.
The loc parameter controls the mean of the function.

The scale parameter controls the standard deviation of the normal distribution.

The size parameter controls the size and shape of the output.

np
​
​
import numpy as np
import pandas as pd
cities = ['Berlin', 'Frankfurt', 'Hamburg', 
          'Nuremberg', 'Munich', 'Stuttgart',
          'Hanover', 'Saarbruecken', 'Cologne',
          'Constance', 'Freiburg', 'Karlsruhe'
         ]
​
n= len(cities)
data = {'Temperature': np.random.normal(24, 3, n),
        'Humidity': np.random.normal(78, 2.5, n),
        'Wind': np.random.normal(15, 4, n)
       }
df = pd.DataFrame(data=data, index=cities)
print(df)



              Temperature   Humidity       Wind
Berlin          24.321236  76.444320  12.470746
Frankfurt       23.772912  82.002832  13.997342
Hamburg         24.384619  80.213384   7.819540
Nuremberg       21.050683  79.034318  17.089984
Munich          27.176935  78.273126  12.182230
Stuttgart       23.880407  86.690017  19.626788
Hanover         22.954061  80.355564  17.715655
Saarbruecken    23.643842  77.755453  15.810944
Cologne         27.579354  77.436512  22.568165
Constance       28.031095  80.500285  16.152888
Freiburg        23.369610  78.784839  22.895745
Karlsruhe       17.689532  75.877155  13.212431
im


import pandas as pd
import pandas.util.testing as tm
import numpy as np
np.random.seed()
tm.makeTimeDataFrame()



A	B	C	D
2000-01-03	-0.247395	-1.512230	-0.363102	-0.086829
2000-01-04	-1.068444	-1.307972	-0.904378	3.041680
2000-01-05	0.248186	0.773102	1.288479	-0.939092
2000-01-06	-0.269264	1.028878	-0.972120	-0.470164
2000-01-07	0.214723	-0.103830	-0.572757	-0.376724
2000-01-10	-0.735516	1.514970	-0.818941	-1.415187
2000-01-11	0.638566	-0.266267	0.123481	-0.174384
2000-01-12	0.177296	3.208390	1.637989	-1.677389
2000-01-13	0.385724	1.887445	0.702634	0.234548
2000-01-14	-0.027401	1.347288	0.251497	0.916821
2000-01-17	-0.784686	0.299302	-0.373968	1.023787
2000-01-18	0.048982	0.949480	0.574546	-0.015756
2000-01-19	1.511327	-0.386531	1.002326	1.167834
2000-01-20	-2.097007	0.851019	0.060791	1.554282
2000-01-21	-0.368826	0.090708	1.016080	0.233551
2000-01-24	-0.147114	-0.351989	-0.241043	0.539106
2000-01-25	0.454945	-0.984934	-1.550111	-0.758388
2000-01-26	-1.626801	-0.392256	-0.255510	0.661852
2000-01-27	-0.842577	0.905880	-0.229460	0.388742
2000-01-28	0.105390	1.270090	-2.332512	0.605277
2000-01-31	0.297928	1.292151	0.625262	-1.296190
2000-02-01	0.147719	0.679976	-0.339256	0.594925
2000-02-02	-0.559867	0.011802	-0.651539	0.348042
2000-02-03	-1.529517	1.773523	-0.506438	-0.648185
2000-02-04	-0.105114	-1.566978	-0.510673	-0.007737
2000-02-07	-0.432893	0.670178	-0.563207	-0.210793
2000-02-08	1.128798	1.639249	-1.107761	-0.603303
2000-02-09	1.129524	-0.733082	-0.590871	1.334341
2000-02-10	-1.265273	0.920165	-1.303221	1.074040
2000-02-11	0.026141	0.328836	1.933001	2.018267
akeDataF

tm.makeDataFrame().shape

(30, 4)
eDataFr
​

tm.makeDataFrame()
A	B	C	D
3zoJ5jhbiN	1.594088	-0.009647	0.050738	-1.422511
08hb0jFUZl	-0.985119	1.513626	1.077517	2.600386
icLQw4kbsK	1.735450	-0.978000	-1.279446	1.437355
uyW2LNzyRT	-1.308267	-0.623734	-0.832153	-0.766387
0G8p8pegoZ	-1.368608	1.312653	1.710034	1.375648
YGSlY4BIkK	1.769594	-1.226006	-0.114095	-0.072109
F52zqVuvUx	-0.815495	-0.044206	-1.264001	0.096424
fb3fLGWmsU	1.232776	-0.886711	1.049367	-0.017850
XhczXbbu9K	0.074895	0.862923	0.403601	-0.520087
Gry9J7Z22u	-2.302298	-1.367346	0.501970	1.318597
80640goa9F	0.091434	-1.085404	0.661736	0.394941
dNp5VrDGK6	1.028640	-1.082691	-0.819587	1.736025
DXHitZgU6q	-0.485641	0.560997	-0.577400	-0.594243
VunQg2Z4Jj	2.330753	-0.176292	-0.453645	0.889622
OQDmbkbb5B	-0.129418	-0.197952	0.634098	1.282614
rMRlNSFPqN	0.901122	0.198416	0.665419	-0.080481
9xyZbW7OXV	-0.751058	-0.038577	-0.293851	-0.887366
ZxtPbso3sA	0.812118	0.184539	0.257691	-0.737505
8T9pxdLF4r	1.731483	0.137799	0.437109	-1.481089
KwDk8BDtJF	1.638244	-0.161702	-1.102482	-0.046019
3LkUh0IRP9	-1.598081	0.282230	-0.017736	-1.176714
u8VGHnLvjq	0.413874	1.078433	-1.358403	-1.272163
ytPQufbq3r	2.376490	-0.368529	-0.196086	1.441501
TWTtYJCrKe	0.202545	-0.017949	0.199047	0.024262
qjVvhkCTaj	0.225527	1.098008	1.423672	-1.449984
gMEFF3t1lo	0.195316	-1.351102	-0.236439	-0.956756
odZv0sIKfO	1.609425	1.045698	0.650507	0.072121
dBShs52xnc	-1.167018	-0.344371	0.401519	-0.422743
3Fh0sBbJTf	0.284313	0.992147	0.733101	0.194380
GYU7MiLv9h	-0.601852	1.098541	0.091415	0.187709
[method for method in dir(tm) if method.startswith('make')]
['makeBoolIndex',
 'makeCategoricalIndex',
 'makeCustomDataframe',
 'makeCustomIndex',
 'makeDataFrame',
 'makeDateIndex',
 'makeFloatIndex',
 'makeFloatSeries',
 'makeIntIndex',
 'makeIntervalIndex',
 'makeMissingDataframe',
 'makeMixedDataFrame',
 'makeMultiIndex',
 'makeObjectSeries',
 'makePeriodFrame',
 'makePeriodIndex',
 'makePeriodSeries',
 'makeRangeIndex',
 'makeStringIndex',
 'makeStringSeries',
 'makeTimeDataFrame',
 'makeTimeSeries',
 'makeTimedeltaIndex',
 'makeUIntIndex',
 'makeUnicodeIndex']
sklearn.datasets.make_blobs(n_samples=100, n_features=2, *, centers=None, cluster_std=1.0, center_box=- 10.0, 10.0, shuffle=True, random_state=None, return_centers=False)
n_samples : int, optional (default=100) The total number of points equally divided among clusters.

n_features : int, optional (default=2) The number of features for each sample.

centers : int or array of shape [n_centers, n_features], optional (default=3) The number of centers to generate, or the fixed center locations.

cluster_std: float or sequence of floats, optional (default=1.0)

The standard deviation of the clusters.

center_box: pair of floats (min, max), optional (default=(-10.0, 10.0)) The bounding box for each cluster center when centers are generated at random.

shuffle : boolean, optional (default=True)

Shuffle the samples.

random_state : int, RandomState instance or None, optional (default=None)

If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by np.random.

Returns X : array of shape [n_samples, n_features] The generated samples.

y : array of shape [n_samples] The integer labels for cluster membership of each sample.

from sklearn.datasets import make_blobs
X, y = make_blobs(n_samples=500, centers=3, n_features=7,random_state=0)
.sha
print(X.shape)
(100, 2)
X
array([[-1.24697941,  2.81973187, -0.33807687,  8.15267823],
       [ 2.89921211,  5.78430212,  3.92282648,  1.80370832],
       [ 9.16271455, -1.31099691,  5.14245091,  2.11427545],
       [-2.12422008,  2.67996053, -2.67231668,  7.34214013],
       [-1.38495085,  2.59855384, -0.55671702,  8.53020916],
       [10.11488647, -2.5806282 ,  5.88399574,  1.07173517],
       [ 8.1464294 , -3.06184738,  5.44962095,  0.67224998],
       [ 9.5595989 , -1.72232579,  4.7892474 ,  1.78904368],
       [ 2.47034915,  4.09862906,  2.36833522,  0.04356792],
       [ 8.83233258, -2.61152512,  5.46980722,  0.73460225],
       [ 0.4666179 ,  3.86571303,  0.80247216,  1.67515402],
       [ 0.28170222,  4.15415279,  1.62011397,  2.74692739],
       [ 8.91982346, -3.94764381,  5.5426634 , -0.18359382],
       [-2.27165884,  2.09144372, -1.3467083 ,  7.17198173],
       [ 7.96672836, -0.67303894,  5.71633672, -0.10227981],
       [ 8.56855493, -1.3879089 ,  6.5816891 , -0.61104656],
       [-0.90167256,  1.31582461, -2.35263911,  7.88762509],
       [ 9.96307337, -1.02932339,  5.2064132 ,  0.09687128],
       [-1.54392443,  3.297034  ,  1.01105318,  7.79320286],
       [ 7.57514939, -1.94388915,  3.57893653, -0.44460845],
       [ 0.11504439,  6.21385228,  1.78726415,  1.70012006],
       [-1.83591698,  1.24187846, -0.09592421,  8.91507861],
       [-0.74057605,  2.45146316, -2.19270203,  7.42541032],
       [-2.33031368,  2.22833248, -1.70378828,  7.85293917],
       [-1.57671974,  4.95740592,  2.91970372,  0.15549864],
       [-3.06770103,  2.98114426, -1.09174924,  8.06764105],
       [-1.56618683,  1.74978876, -0.72497911,  7.66391368],
       [-0.33887422,  3.23482487, -0.32739695,  8.15418767],
       [ 1.0427873 ,  4.60625923,  1.42094543,  0.53492249],
       [10.92139014, -2.16694187,  6.40179104,  0.35522329],
       [ 1.5528609 ,  4.09548857,  2.45127423, -0.19539785],
       [ 8.67460127, -3.44706661,  6.60116394,  0.93419121],
       [-0.75511346,  3.74138642,  0.91498017,  9.17198797],
       [-1.88089792,  1.54293097, -1.89187418,  5.61205686],
       [ 7.43018566, -2.80914363,  5.35484495,  1.19825669],
       [-2.84281142,  2.45629766, -1.31649738,  9.54880274],
       [ 9.93963829, -2.79188941,  4.50024229, -0.76881911],
       [ 9.2575731 , -2.17024146,  5.64384727,  0.18304888],
       [ 1.35269561,  3.20438654,  2.3535057 ,  2.22404956],
       [ 8.11589995, -2.64346187,  5.67683375,  2.83462189],
       [-1.03316224,  2.80177832, -3.27894024,  9.89995288],
       [11.57717191, -3.39118545,  5.69855106,  1.71478976],
       [-2.16434104,  2.52061045, -1.38113635,  7.53766914],
       [ 2.50904929,  5.7731461 ,  2.21021495,  1.27582618],
       [ 3.35941485,  5.24826681,  1.1424453 ,  2.01467995],
       [ 0.06897171,  4.35573272,  2.78435808,  1.02664657],
       [-2.75233953,  3.76224524, -2.24847112,  6.29068892],
       [-2.25250139,  1.53451831, -2.83119417,  8.44583939],
       [-2.26646701,  4.46089686, -2.54111268,  8.10251088],
       [-2.06976549,  3.33393231, -2.40443821,  8.61665812],
       [-0.18887976,  5.20461381,  2.52092996, -0.63858003],
       [-0.03241947,  0.84789724, -0.82199704,  8.51236805],
       [10.34176461, -2.78455543,  5.14666315, -0.63617901],
       [ 0.4290083 ,  3.30797558, -1.90066436,  7.44450664],
       [ 1.18454506,  5.28042636,  2.41163392,  1.60423683],
       [-0.63762777,  4.09104705,  1.15980096,  1.28456616],
       [ 9.31188576, -3.98788473,  4.84899002, -0.89393661],
       [ 0.10547293,  3.72493766,  1.74371499,  0.953829  ],
       [ 7.51736463, -1.88023516,  5.15048986,  2.23744919],
       [ 3.2460247 ,  2.84942165,  2.10102604,  0.71047981],
       [ 8.55365082, -3.14416261,  6.10901712, -0.31301669],
       [ 9.85177671, -1.98151517,  5.07035684, -0.85989308],
       [-0.19685333,  6.24740851,  1.64164854,  0.15020885],
       [ 1.7373078 ,  4.42546234,  2.49913075,  1.23133799],
       [ 9.96702836, -2.49074306,  5.7007992 ,  1.6556422 ],
       [-2.48284901,  2.57190049, -1.71185175,  8.31694149],
       [-0.07228289,  2.88376939,  0.34899733,  2.84843906],
       [10.13117913, -1.19006776,  7.30107948,  1.43045033],
       [ 9.97171236, -2.32739873,  6.76634914,  0.91786338],
       [ 9.37098018, -1.74821594,  5.43505173,  0.94795428],
       [-0.40026809,  1.83795075, -2.39572443,  7.39763997],
       [ 9.91656968, -3.90179303,  5.62759709,  1.45807731],
       [-0.09448254,  5.35823905,  1.65209057,  2.12010873],
       [ 2.85942078,  2.95602827,  0.78478252,  1.86706037],
       [ 1.64856484,  4.71124916,  1.28535145,  1.43691285],
       [-1.83779018,  3.01528243, -0.84920943,  5.06286726],
       [ 0.30380963,  3.94423417,  1.24212124, -0.82861894],
       [ 0.46546494,  3.12315514,  2.02708529,  1.32599553],
       [ 9.08820154, -3.13881811,  4.38796606,  1.37819634],
       [-0.51498751,  4.74317903,  2.22194102,  1.5326951 ],
       [10.04650819, -3.51505026,  3.17532852,  1.18421792],
       [-2.34026827,  1.45145793, -0.7271909 ,  7.25967205],
       [-2.02493646,  4.84741432, -0.29883497,  7.92301126],
       [-3.46318382,  3.10666086, -0.72436475,  7.9238821 ],
       [ 2.11567076,  3.06896151,  2.45760916,  0.21285357],
       [ 0.08848433,  2.32299086,  1.70735537,  1.05401263],
       [ 0.30193742,  4.33561789,  1.41942144,  1.57409695],
       [ 1.92352205,  4.14877723,  2.66934689,  1.81987033],
       [-0.6700734 ,  2.26685667, -2.28249862,  8.51705453],
       [-0.88677249,  1.30092622, -1.2725819 ,  7.09742911],
       [ 2.20656076,  5.50616718,  1.6679407 ,  0.59536091],
       [10.63778706, -3.02061881,  5.18220716,  0.05670908],
       [ 1.15369622,  3.90200639,  0.42506917,  1.36044592],
       [ 9.00552167, -3.45918095,  6.11494247, -0.41522522],
       [ 2.46452227,  6.1996765 ,  3.23404709,  0.71773882],
       [ 0.9867701 ,  6.08965782,  2.18217961,  1.29965302],
       [ 7.50471676, -1.97568783,  6.64902058,  0.63682398],
       [-1.89608585,  2.67850308, -0.14859618,  8.49072375],
       [ 9.23108376, -2.61805682,  5.77287436,  0.47059312],
       [-2.71576327,  2.41106591, -1.84456981,  7.78289272]])
y
array([1, 0, 1, 0, 0, 0, 2, 2, 1, 0, 0, 0, 1, 0, 2, 1, 2, 0, 2, 2, 2, 2,
       2, 0, 1, 1, 1, 1, 2, 2, 0, 1, 1, 0, 2, 2, 0, 1, 1, 2, 2, 1, 1, 0,
       0, 0, 1, 1, 2, 2, 2, 1, 0, 1, 2, 2, 1, 1, 0, 1, 1, 2, 2, 2, 2, 1,
       0, 2, 1, 0, 2, 0, 0, 1, 1, 0, 0, 0, 2, 1, 0, 0, 1, 0, 1, 0, 0, 0,
       1, 0, 1, 1, 2, 2, 2, 2, 0, 0, 2, 2])
ke_blobs()
​
​
X,y = make_blobs()
X
array([[-6.42960177e-03,  3.49962761e+00,  8.57080808e-01, ...,
        -1.30937847e+00,  5.00232395e+00,  2.65220316e-01],
       [-9.00676740e+00, -8.04778807e+00, -8.86760267e+00, ...,
         6.37716526e+00,  6.11092953e+00,  1.13112463e+01],
       [-8.21709754e+00, -7.51321782e+00, -1.04114179e+01, ...,
         6.29378151e+00,  8.53596944e+00,  8.12065930e+00],
       ...,
       [-2.12974603e-02,  3.50374911e+00,  2.26234310e+00, ...,
        -2.22629883e+00,  3.83158807e+00, -1.92104056e+00],
       [-8.81083073e+00, -8.38711790e+00, -1.07359754e+01, ...,
         5.87844146e+00,  6.07917452e+00,  1.00841964e+01],
       [ 2.83499502e-01,  5.44161419e+00,  1.88611027e+00, ...,
        -2.02497712e+00,  2.55499115e+00, -9.84295466e-01]])
y
array([0, 2, 2, 0, 0, 2, 2, 2, 2, 1, 2, 1, 0, 0, 2, 0, 0, 1, 1, 0, 2, 1,
       2, 1, 1, 1, 0, 2, 1, 2, 1, 2, 2, 1, 1, 1, 1, 2, 2, 1, 0, 1, 2, 0,
       2, 2, 2, 2, 2, 1, 1, 2, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2, 2, 2, 2, 0,
       2, 2, 0, 2, 2, 2, 2, 0, 1, 1, 0, 0, 0, 1, 2, 2, 0, 0, 2, 1, 1, 2,
       2, 2, 1, 0, 2, 1, 0, 2, 1, 1, 0, 1, 0, 1, 1, 1, 2, 2, 0, 1, 1, 2,
       2, 2, 0, 2, 1, 0, 2, 1, 2, 2, 1, 2, 2, 1, 1, 2, 1, 0, 2, 2, 2, 0,
       2, 1, 2, 1, 0, 0, 0, 1, 2, 0, 0, 0, 2, 2, 2, 0, 1, 1, 0, 1, 1, 0,
       0, 1, 2, 1, 0, 2, 1, 0, 1, 2, 0, 2, 0, 0, 0, 0, 1, 0, 2, 0, 1, 0,
       2, 1, 1, 0, 2, 0, 2, 0, 1, 2, 1, 1, 1, 0, 2, 1, 1, 2, 1, 2, 0, 1,
       0, 2, 0, 0, 0, 2, 1, 0, 0, 0, 2, 0, 1, 2, 2, 2, 0, 1, 0, 2, 1, 0,
       0, 1, 0, 1, 1, 2, 0, 1, 0, 2, 0, 2, 0, 1, 1, 2, 0, 0, 1, 2, 0, 0,
       0, 1, 0, 2, 0, 2, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 2, 1, 0, 0, 2, 2,
       0, 0, 1, 1, 2, 0, 1, 0, 2, 0, 1, 0, 1, 2, 0, 1, 0, 1, 0, 0, 1, 1,
       0, 2, 1, 2, 0, 0, 0, 2, 0, 1, 2, 0, 0, 2, 1, 1, 2, 2, 1, 0, 2, 1,
       0, 1, 2, 1, 1, 2, 1, 0, 1, 1, 2, 0, 0, 1, 1, 2, 1, 2, 1, 1, 0, 0,
       1, 2, 0, 2, 1, 1, 1, 0, 1, 0, 1, 0, 2, 1, 0, 0, 0, 0, 2, 1, 0, 2,
       1, 2, 2, 2, 2, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 2, 1, 0, 1,
       1, 2, 2, 2, 1, 1, 2, 2, 1, 2, 2, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0,
       0, 0, 1, 1, 2, 0, 0, 1, 2, 2, 2, 1, 2, 0, 1, 1, 0, 2, 0, 2, 0, 2,
       0, 0, 1, 0, 0, 1, 2, 2, 2, 1, 0, 1, 2, 0, 1, 2, 1, 2, 2, 2, 1, 1,
       2, 1, 2, 0, 1, 2, 2, 0, 2, 2, 1, 1, 2, 1, 2, 1, 0, 1, 0, 2, 2, 2,
       1, 1, 2, 1, 1, 2, 0, 1, 2, 1, 1, 2, 0, 0, 0, 2, 1, 0, 1, 1, 1, 1,
       2, 2, 0, 2, 1, 0, 1, 1, 0, 2, 0, 0, 0, 0, 2, 0])
Dictionary in Python is a collection of data values which only maintains the order of insertion, used to store data values like a map, which, unlike other Data Types that hold only a single value as an element, Dictionary holds key: value pair.
keys() method in Python Dictionary, returns a view object that displays a list of all the keys in the dictionary in order of insertion.

Syntax: dict.keys()

Parameters: There are no parameters.

Returns: A view object is returned that displays all the keys. This view object changes according to the changes in the dictionary.

(Dictionary1.keys())
 
# Python program to show working
# of keys in Dictionary
 
# Dictionary with three keys
Dictionary1 = {'A': 'america', 'B': 'bombay', 'C': 'chennai'}
 
# Printing keys of dictionary
print(Dictionary1.keys())
 
# Creating empty Dictionary
empty_Dict1 = {}
 
# Printing keys of Empty Dictionary
print(empty_Dict1.keys())
dict_keys(['A', 'B', 'C'])
dict_keys([])
oad_digits
from sklearn.datasets import load_digits
digits = load_digits()
digits.keys()
​
dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])
n_samples
n_samples, n_features = digits.data.shape
print((n_samples, n_features))
​
(1797, 64)
digits.feature_names
​
['pixel_0_0',
 'pixel_0_1',
 'pixel_0_2',
 'pixel_0_3',
 'pixel_0_4',
 'pixel_0_5',
 'pixel_0_6',
 'pixel_0_7',
 'pixel_1_0',
 'pixel_1_1',
 'pixel_1_2',
 'pixel_1_3',
 'pixel_1_4',
 'pixel_1_5',
 'pixel_1_6',
 'pixel_1_7',
 'pixel_2_0',
 'pixel_2_1',
 'pixel_2_2',
 'pixel_2_3',
 'pixel_2_4',
 'pixel_2_5',
 'pixel_2_6',
 'pixel_2_7',
 'pixel_3_0',
 'pixel_3_1',
 'pixel_3_2',
 'pixel_3_3',
 'pixel_3_4',
 'pixel_3_5',
 'pixel_3_6',
 'pixel_3_7',
 'pixel_4_0',
 'pixel_4_1',
 'pixel_4_2',
 'pixel_4_3',
 'pixel_4_4',
 'pixel_4_5',
 'pixel_4_6',
 'pixel_4_7',
 'pixel_5_0',
 'pixel_5_1',
 'pixel_5_2',
 'pixel_5_3',
 'pixel_5_4',
 'pixel_5_5',
 'pixel_5_6',
 'pixel_5_7',
 'pixel_6_0',
 'pixel_6_1',
 'pixel_6_2',
 'pixel_6_3',
 'pixel_6_4',
 'pixel_6_5',
 'pixel_6_6',
 'pixel_6_7',
 'pixel_7_0',
 'pixel_7_1',
 'pixel_7_2',
 'pixel_7_3',
 'pixel_7_4',
 'pixel_7_5',
 'pixel_7_6',
 'pixel_7_7']
digits
print (digits.DESCR)
.. _digits_dataset:

Optical recognition of handwritten digits dataset
--------------------------------------------------

**Data Set Characteristics:**

    :Number of Instances: 1797
    :Number of Attributes: 64
    :Attribute Information: 8x8 image of integer pixels in the range 0..16.
    :Missing Attribute Values: None
    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)
    :Date: July; 1998

This is a copy of the test set of the UCI ML hand-written digits datasets
https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits

The data set contains images of hand-written digits: 10 classes where
each class refers to a digit.

Preprocessing programs made available by NIST were used to extract
normalized bitmaps of handwritten digits from a preprinted form. From a
total of 43 people, 30 contributed to the training set and different 13
to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of
4x4 and the number of on pixels are counted in each block. This generates
an input matrix of 8x8 where each element is an integer in the range
0..16. This reduces dimensionality and gives invariance to small
distortions.

For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.
T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.
L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,
1994.

.. topic:: References

  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their
    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of
    Graduate Studies in Science and Engineering, Bogazici University.
  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.
  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.
    Linear dimensionalityreduction using relevance weighted LDA. School of
    Electrical and Electronic Engineering Nanyang Technological University.
    2005.
  - Claudio Gentile. A New Approximate Maximal Margin Classification
    Algorithm. NIPS. 2000.

eatures=
from sklearn.datasets import make_blobs
​
from matplotlib import pyplot
​
from pandas import DataFrame
​
# generate 2d classification dataset
X, y = make_blobs(n_samples=100, centers=3, n_features=2)
​
# scatter plot, dots colored by class value
df = DataFrame(dict(x=X[:,0], y=X[:,1], label=y))
​
colors = {0:'red', 1:'blue', 2:'green'}
​
fig, ax = pyplot.subplots()
​
grouped = df.groupby('label')
​
for key, group in grouped:
    group.plot(ax=ax, kind='scatter', x='x', y='y', label=key, color=colors[key])
pyplot.show()

​


from sklearn.datasets import make_moons
​
from matplotlib import pyplot
​
from pandas import DataFrame
​
# generate 2d classification dataset
X, y = make_moons(n_samples=100, noise=0.1)
​
# scatter plot, dots colored by class value
df = DataFrame(dict(x=X[:,0], y=X[:,1], label=y))
​
colors = {0:'red', 1:'blue'}
​
fig, ax = pyplot.subplots()
​
grouped = df.groupby('label')
​
for key, group in grouped:
    group.plot(ax=ax, kind='scatter', x='x', y='y', label=key, color=colors[key])
pyplot.show()

from sklearn.datasets import make_circles
​
from matplotlib import pyplot
​
from pandas import DataFrame
​
# generate 2d classification dataset
X, y = make_circles(n_samples=100, noise=0.05)
​
# scatter plot, dots colored by class value
df = DataFrame(dict(x=X[:,0], y=X[:,1], label=y))
​
colors = {0:'red', 1:'blue'}
​
fig, ax = pyplot.subplots()
​
grouped = df.groupby('label')
for key, group in grouped:
    group.plot(ax=ax, kind='scatter', x='x', y='y', label=key, color=colors[key])
pyplot.show()

​
from sklearn.datasets import make_regression
​
from matplotlib import pyplot
​
# generate regression dataset
X, y = make_regression(n_samples=100, n_features=1, noise=0.1)
print(X)
print(y)
# plot regression dataset
pyplot.scatter(X,y)
pyplot.show()
[[-2.57925991]
 [-0.74410592]
 [ 0.23082166]
 [-0.57873296]
 [-0.74114496]
 [ 0.28078681]
 [-0.03387723]
 [-1.50079124]
 [ 1.44552009]
 [ 0.92423457]
 [-0.26776338]
 [-0.11504704]
 [-0.86709542]
 [-0.86681503]
 [ 0.78897127]
 [-0.05903026]
 [-0.1059884 ]
 [-2.11273514]
 [-0.61551542]
 [ 0.62111978]
 [ 0.33457527]
 [-1.35939989]
 [ 1.2477495 ]
 [ 1.52571678]
 [-0.26708184]
 [-0.75071641]
 [ 0.36314013]
 [-0.29124236]
 [ 1.86405946]
 [-0.37929544]
 [ 3.05063711]
 [ 0.66918187]
 [-0.77242333]
 [-0.15216706]
 [-0.23198053]
 [-0.25909451]
 [ 0.14408411]
 [ 0.45399236]
 [ 0.35807899]
 [ 2.08595172]
 [-1.02929694]
 [ 1.76164303]
 [ 0.24367435]
 [-0.63890345]
 [ 2.26856923]
 [ 0.06144891]
 [-1.28092525]
 [ 0.88318495]
 [-0.64781359]
 [ 0.20667734]
 [-0.68916949]
 [ 1.33891765]
 [ 0.32599175]
 [ 0.30620509]
 [ 0.89773952]
 [ 1.28230841]
 [ 1.51920396]
 [ 0.1969163 ]
 [ 2.07492881]
 [-0.94063226]
 [ 0.09841466]
 [ 0.51411475]
 [-0.35958082]
 [ 0.87781879]
 [-0.52573228]
 [ 0.56803964]
 [-0.0324972 ]
 [ 1.11067726]
 [-0.88266494]
 [ 1.19627181]
 [ 0.34201384]
 [ 0.94854337]
 [-0.9434946 ]
 [-0.2724346 ]
 [ 1.3776324 ]
 [ 0.69532239]
 [-0.50004637]
 [ 0.3199692 ]
 [ 1.3709985 ]
 [-0.13835283]
 [-0.04881303]
 [ 0.34046917]
 [-0.66186516]
 [-0.97871709]
 [-0.35711187]
 [-1.16919185]
 [ 1.04199643]
 [-0.2876534 ]
 [ 0.0968941 ]
 [ 2.89955371]
 [-0.91288792]
 [-2.94504905]
 [ 2.8257332 ]
 [-0.20708353]
 [ 1.00655944]
 [-1.17711062]
 [-0.15571988]
 [ 0.73991151]
 [-2.17111206]
 [-1.31966975]]
[-1.40432881e+01 -4.12941722e+00  1.21778532e+00 -3.20542697e+00
 -3.88457386e+00  1.56926576e+00 -3.68879226e-01 -8.26020288e+00
  7.84501029e+00  5.06697483e+00 -1.36279399e+00 -7.37615008e-01
 -4.69437876e+00 -4.52663107e+00  4.22245632e+00  9.69103551e-03
 -6.72784058e-01 -1.15726772e+01 -3.39366653e+00  3.29064171e+00
  1.80911794e+00 -7.46333185e+00  6.79003849e+00  8.29562916e+00
 -1.36877239e+00 -3.94120797e+00  2.01411380e+00 -1.66033701e+00
  1.03532171e+01 -2.16773924e+00  1.67758706e+01  3.69789354e+00
 -4.17598748e+00 -7.58272095e-01 -1.36152236e+00 -1.34488298e+00
  6.23533498e-01  2.42909577e+00  1.94702230e+00  1.11955819e+01
 -5.55244360e+00  9.55235600e+00  1.37308104e+00 -3.38454999e+00
  1.21784979e+01  3.50544675e-01 -6.84685325e+00  4.76836854e+00
 -3.63968144e+00  1.11215431e+00 -3.74516840e+00  7.20427094e+00
  1.66388799e+00  1.68043273e+00  4.95712222e+00  7.16048874e+00
  8.32840802e+00  9.59975259e-01  1.13040144e+01 -5.02475309e+00
  6.17857049e-01  2.94804967e+00 -2.00616417e+00  4.67424810e+00
 -2.93546290e+00  3.24495300e+00 -2.10220820e-02  5.92828453e+00
 -4.66954529e+00  6.51852474e+00  1.76344518e+00  5.23892773e+00
 -5.13043173e+00 -1.54602983e+00  7.53406773e+00  3.75576104e+00
 -2.61892913e+00  1.80143005e+00  7.57064460e+00 -9.18010446e-01
 -1.47452867e-01  1.77775005e+00 -3.53802449e+00 -5.43633818e+00
 -2.02365020e+00 -6.27316621e+00  5.65228196e+00 -1.65742475e+00
  5.97089477e-01  1.58853975e+01 -5.03837113e+00 -1.59302822e+01
  1.54916713e+01 -1.21525344e+00  5.46787281e+00 -6.49679531e+00
 -8.41562496e-01  3.98187865e+00 -1.18650495e+01 -7.27244364e+00]

from sklearn.datasets import make_classification
from sklearn.datasets import make_classification
#from sklearn.datasets import make_regression
#from sklearn.datasets import make_blobs
X,y = make_classification (n_samples=100, n_features=6)
X
array([[ 1.11359378,  0.24366064, -0.58391828,  0.60747656,  0.63702873,
         1.21504448],
       [-1.12774677,  1.4673656 ,  0.01660127, -0.99330346,  0.65104155,
         0.23865209],
       [ 0.43892851, -0.0482018 , -0.57061793,  0.01545714,  1.01891165,
        -0.80548954],
       ...,
       [ 0.50916722,  0.13322194, -0.79686395, -0.07083914,  1.48626811,
        -1.04132958],
       [-0.17706708, -1.80826707, -0.82859647, -0.70278647,  1.97677329,
        -1.45584531],
       [ 1.19893311, -2.775387  , -0.47625064,  0.75430063,  0.34211447,
        -1.76727153]])
y
array([1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1,
       1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1,
       1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1,
       0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0,
       0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1])
X,y = make_classification (n_samples=100, n_features=20,
                           n_informative=5,
                           n_redundant=1,
                           n_repeated=1,
                           n_classes=3, 
                           n_clusters_per_class=1, 
                           hypercube=False, 
                           shift=None,scale=None, 
                           weights=[0.1, 0.25],
                          random_state=0)
X
X
array([[  29.568076  ,   14.35316258,   58.03334524, ...,   64.51714597,
         -84.18215588,  -19.99766307],
       [  16.49171463,  -54.785029  ,  129.30115897, ...,  -51.85159117,
        -113.08959885,   44.32086593],
       [ -27.04053195,  -30.10819447,  -18.93253963, ...,  101.44777187,
         -47.47631165,  -63.47426724],
       ...,
       [ -56.33912532,  -42.8829325 ,   48.35488233, ...,   39.24301094,
          23.40598401,   37.15353431],
       [ -67.25163471,   33.28265579,  -16.47776853, ...,   46.86134654,
          57.46695192,   64.41141774],
       [ -51.04642793,  -88.59510805,  107.97132999, ...,   35.41039886,
         150.63675375,  122.88711397]])
y
array([0, 2, 2, 0, 0, 2, 2, 2, 2, 1, 2, 1, 0, 0, 2, 0, 0, 1, 1, 0, 2, 1,
       2, 1, 1, 1, 0, 2, 1, 2, 1, 2, 2, 1, 1, 1, 1, 2, 2, 1, 0, 1, 2, 0,
       2, 2, 2, 2, 2, 1, 1, 2, 1, 1, 0, 1, 1, 2, 2, 0, 2, 2, 2, 2, 2, 0,
       2, 2, 0, 2, 2, 2, 2, 0, 1, 1, 0, 0, 0, 1, 2, 2, 0, 0, 2, 1, 1, 2,
       2, 2, 1, 0, 2, 1, 0, 2, 1, 1, 0, 1, 0, 1, 1, 1, 2, 2, 0, 1, 1, 2,
       2, 2, 0, 2, 1, 0, 2, 1, 2, 2, 1, 2, 2, 1, 1, 2, 1, 0, 2, 2, 2, 0,
       2, 1, 2, 1, 0, 0, 0, 1, 2, 0, 0, 0, 2, 2, 2, 0, 1, 1, 0, 1, 1, 0,
       0, 1, 2, 1, 0, 2, 1, 0, 1, 2, 0, 2, 0, 0, 0, 0, 1, 0, 2, 0, 1, 0,
       2, 1, 1, 0, 2, 0, 2, 0, 1, 2, 1, 1, 1, 0, 2, 1, 1, 2, 1, 2, 0, 1,
       0, 2, 0, 0, 0, 2, 1, 0, 0, 0, 2, 0, 1, 2, 2, 2, 0, 1, 0, 2, 1, 0,
       0, 1, 0, 1, 1, 2, 0, 1, 0, 2, 0, 2, 0, 1, 1, 2, 0, 0, 1, 2, 0, 0,
       0, 1, 0, 2, 0, 2, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 2, 1, 0, 0, 2, 2,
       0, 0, 1, 1, 2, 0, 1, 0, 2, 0, 1, 0, 1, 2, 0, 1, 0, 1, 0, 0, 1, 1,
       0, 2, 1, 2, 0, 0, 0, 2, 0, 1, 2, 0, 0, 2, 1, 1, 2, 2, 1, 0, 2, 1,
       0, 1, 2, 1, 1, 2, 1, 0, 1, 1, 2, 0, 0, 1, 1, 2, 1, 2, 1, 1, 0, 0,
       1, 2, 0, 2, 1, 1, 1, 0, 1, 0, 1, 0, 2, 1, 0, 0, 0, 0, 2, 1, 0, 2,
       1, 2, 2, 2, 2, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 2, 1, 0, 1,
       1, 2, 2, 2, 1, 1, 2, 2, 1, 2, 2, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0,
       0, 0, 1, 1, 2, 0, 0, 1, 2, 2, 2, 1, 2, 0, 1, 1, 0, 2, 0, 2, 0, 2,
       0, 0, 1, 0, 0, 1, 2, 2, 2, 1, 0, 1, 2, 0, 1, 2, 1, 2, 2, 2, 1, 1,
       2, 1, 2, 0, 1, 2, 2, 0, 2, 2, 1, 1, 2, 1, 2, 1, 0, 1, 0, 2, 2, 2,
       1, 1, 2, 1, 1, 2, 0, 1, 2, 1, 1, 2, 0, 0, 0, 2, 1, 0, 1, 1, 1, 1,
       2, 2, 0, 2, 1, 0, 1, 1, 0, 2, 0, 0, 0, 0, 2, 0])
X,y = make_classification (n_samples=100, n_features=20,
                           n_informative=5,
                           n_redundant=1,
                           n_repeated=1,
                           n_classes=3, # SUMMER  WINTER AUT
                           n_clusters_per_class=1, 
                           hypercube=False, 
                           shift=None,scale=None, 
                           weights=[0.25, 0.25],
                          random_state=123)
y
array([1, 0, 0, 2, 2, 0, 0, 1, 0, 2, 2, 2, 2, 2, 2, 1, 0, 2, 2, 1, 0, 1,
       2, 2, 0, 0, 2, 1, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 0, 2, 2,
       1, 2, 2, 1, 2, 1, 0, 1, 2, 2, 0, 2, 0, 1, 2, 0, 2, 1, 1, 2, 1, 2,
       2, 2, 2, 2, 0, 2, 2, 1, 0, 2, 1, 2, 2, 2, 2, 1, 1, 1, 2, 0, 1, 0,
       0, 1, 1, 0, 1, 2, 0, 0, 0, 1, 1, 2])
X,y = make_classification (n_samples=100, n_features=20,
                           n_informative=5,
                           n_redundant=1,
                           n_repeated=1,
                           n_classes=3, 
                           n_clusters_per_class=1, 
                           hypercube=False, 
                           shift=None,scale=None, 
                           weights=[0.50, 0.50],
                          random_state=0)
y
array([0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,
       0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0,
       0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1,
       1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1,
       0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0])
y = make_classification (n_samples=100, n_features=20,
                           n_informative=5,
                           n_redundant=1,
                           n_repeated=1,
                           n_classes=3, 
                           n_clusters_per_class=1, 
                           hypercube=False, 
                           shift=None,scale=None, 
                           weights=[0.70, 0.20],
                          random_state=12)
X,y = make_classification (n_samples=100, n_features=20,
                           n_informative=5,
                           n_redundant=1,
                           n_repeated=1,
                           n_classes=3, 
                           n_clusters_per_class=1, 
                           hypercube=False, 
                           shift=None,scale=None, 
                           weights=[0.70, 0.20],
                          random_state=12)
y
array([0, 0, 0, 0, 1, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 2,
       0, 1, 0, 2, 0, 1, 0, 1, 0, 2, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0,
       1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 2, 2, 0, 0, 0, 1,
       0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0,
       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0])
X,y = make_classification (n_samples=100, n_features=20,
                           n_informative=5,
                           n_redundant=1,
                           n_repeated=1,
                           n_classes=3, 
                           n_clusters_per_class=1, 
                           hypercube=False, 
                           shift=None,scale=None, 
                           weights=[0.70, 0.20],
                          random_state=1234)
X
array([[  -0.423384  ,  -32.75980063,   36.87880291, ...,   82.86298242,
          -6.26783506,   56.87120641],
       [   0.47732816,   49.66628731,  -61.05286006, ...,  190.52379208,
           8.95682073,  124.45123306],
       [  -1.13469587,   19.33704274,  279.4313817 , ...,  121.03684113,
         -35.73142327,   16.22324205],
       ...,
       [  -1.0442674 ,  -81.67468087,  147.58005548, ...,  119.95613397,
         -27.39131745,  -16.88676533],
       [   1.53083844,  -33.90750226,  -86.27709805, ...,   65.33770545,
          -9.61118386,   -7.47588458],
       [   0.34329715, -115.68762902, -121.64996714, ...,  -36.50693796,
           3.33398176,  -85.15825564]])
from sklearn.datasets import load_digits
digits = load_digits()
digits.keys()
dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])
n_samples, n_features = digits.data.shape
print((n_samples, n_features))
(1797, 64)
print(digits.data[0])
print(digits.target)
[ 0.  0.  5. 13.  9.  1.  0.  0.  0.  0. 13. 15. 10. 15.  5.  0.  0.  3.
 15.  2.  0. 11.  8.  0.  0.  4. 12.  0.  0.  8.  8.  0.  0.  5.  8.  0.
  0.  9.  8.  0.  0.  4. 11.  0.  1. 12.  7.  0.  0.  2. 14.  5. 10. 12.
  0.  0.  0.  0.  6. 13. 10.  0.  0.  0.]
[0 1 2 ... 8 9 8]